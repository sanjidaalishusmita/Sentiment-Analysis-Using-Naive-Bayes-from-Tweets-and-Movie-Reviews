{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6334d99",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc7eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ed81e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4bf868",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b43e905b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "1       A series of escapades demonstrating the adage ...          2  \n",
       "2                                                A series          2  \n",
       "3                                                       A          2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                          Hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "rt_data = pd.read_csv('RT_train.tsv', sep='\\t')\n",
    "\n",
    "rt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d79b61ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206.3578110982955"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rt_data['Sentiment'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a8830f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(rt_data['Phrase'], \n",
    "                                                    rt_data['Sentiment'], \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd75fb8d",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7add7c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "vect = CountVectorizer().fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "clfrNB = MultinomialNB(alpha = 0.1)\n",
    "clfrNB.fit(X_train_vectorized, Y_train)\n",
    "predicted_labels = clfrNB.predict(X_test_vectorized)\n",
    "score = accuracy_score(Y_test, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "973ef094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6003588363449955"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "337dc560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fit & Transform X_train using Tfidf Vectorizer & get the feature names. {My Note}\n",
    "vect = TfidfVectorizer().fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "    \n",
    "# Sort index to get the top feature names. {My Note}\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "Sindex = feature_names[sorted_tfidf_index[:20]]\n",
    "Lindex = feature_names[sorted_tfidf_index[:-21:-1]]\n",
    "    \n",
    "# Create a DataFrame(Sparse) with all the scores and get the max of each row to get the sorted Series. {My Note}\n",
    "df = pd.DataFrame(X_train_vectorized.toarray(), columns = vect.get_feature_names_out())\n",
    "Series = sorted(df.max())\n",
    "    \n",
    "# Sort the smallest tf-idfs based on Score and then Alphabetically. {My Note}\n",
    "Sdf = pd.DataFrame(Series[:20],index = Sindex)\n",
    "Sdf = Sdf.reset_index()\n",
    "Sdf = Sdf.sort_values([0, \"index\"], ascending = (True, True))\n",
    "Sdf = Sdf.set_index('index')\n",
    "Sseries = pd.Series(Sdf[0], index = Sdf.index)\n",
    "# Sort the largest tf-idfs based on Score and then Alphabetically. {My Note}\n",
    "Ldf = pd.DataFrame(Series[:-21:-1],index = Lindex)\n",
    "Ldf = Ldf.reset_index()\n",
    "Ldf = Ldf.sort_values([0, \"index\"], ascending = (False, True))\n",
    "Ldf = Ldf.set_index('index')\n",
    "Lseries = pd.Series(Ldf[0], index = Ldf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41589510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "cheated         1.0\n",
       "cheatfully      1.0\n",
       "cheats          1.0\n",
       "journalist      1.0\n",
       "journalistic    1.0\n",
       "journalists     1.0\n",
       "journey         1.0\n",
       "jovial          1.0\n",
       "joy             1.0\n",
       "joyful          1.0\n",
       "joyless         1.0\n",
       "joylessly       1.0\n",
       "joyous          1.0\n",
       "jr              1.0\n",
       "juan            1.0\n",
       "judaism         1.0\n",
       "judd            1.0\n",
       "judge           1.0\n",
       "judgment        1.0\n",
       "zzzzzzzzz       1.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f51c58e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "managing            0.228233\n",
       "cineasts            0.261518\n",
       "ackerman            0.271927\n",
       "grounds             0.288356\n",
       "uproariously        0.300387\n",
       "ashamed             0.304002\n",
       "preposterousness    0.306089\n",
       "documented          0.310805\n",
       "helpful             0.310888\n",
       "shamefully          0.312022\n",
       "downplays           0.315960\n",
       "clotted             0.318975\n",
       "suspenser           0.320186\n",
       "woozy               0.320806\n",
       "fools               0.321918\n",
       "provocateur         0.322897\n",
       "devise              0.324900\n",
       "trimmed             0.325637\n",
       "fuddled             0.326940\n",
       "errs                0.328282\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84bcebc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5998205818275022"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vectorized = vect.transform(X_test)\n",
    "clfrNB = MultinomialNB(alpha = 0.1)\n",
    "clfrNB.fit(X_train_vectorized, Y_train)\n",
    "predicted_labels = clfrNB.predict(X_test_vectorized)\n",
    "score = accuracy_score(Y_test, predicted_labels)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de2d1d3",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63f1246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer().fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "clfrNB2 = BernoulliNB(alpha=0.1)\n",
    "clfrNB2.fit(X_train_vectorized, Y_train)\n",
    "predicted_labels = clfrNB2.predict(X_test_vectorized)\n",
    "score = accuracy_score(Y_test, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe39c1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5989491221325132"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "099de070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit & Transform X_train using Tfidf Vectorizer & get the feature names. {My Note}\n",
    "vect = TfidfVectorizer().fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "    \n",
    "# Sort index to get the top feature names. {My Note}\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "Sindex = feature_names[sorted_tfidf_index[:20]]\n",
    "Lindex = feature_names[sorted_tfidf_index[:-21:-1]]\n",
    "    \n",
    "# Create a DataFrame(Sparse) with all the scores and get the max of each row to get the sorted Series. {My Note}\n",
    "df = pd.DataFrame(X_train_vectorized.toarray(), columns = vect.get_feature_names_out())\n",
    "Series = sorted(df.max())\n",
    "    \n",
    "# Sort the smallest tf-idfs based on Score and then Alphabetically. {My Note}\n",
    "Sdf = pd.DataFrame(Series[:20],index = Sindex)\n",
    "Sdf = Sdf.reset_index()\n",
    "Sdf = Sdf.sort_values([0, \"index\"], ascending = (True, True))\n",
    "Sdf = Sdf.set_index('index')\n",
    "Sseries = pd.Series(Sdf[0], index = Sdf.index)\n",
    "# Sort the largest tf-idfs based on Score and then Alphabetically. {My Note}\n",
    "Ldf = pd.DataFrame(Series[:-21:-1],index = Lindex)\n",
    "Ldf = Ldf.reset_index()\n",
    "Ldf = Ldf.sort_values([0, \"index\"], ascending = (False, True))\n",
    "Ldf = Ldf.set_index('index')\n",
    "Lseries = pd.Series(Ldf[0], index = Ldf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37888267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5989491221325132"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vectorized = vect.transform(X_test)\n",
    "clfrNB2 = BernoulliNB(alpha = 0.1)\n",
    "clfrNB2.fit(X_train_vectorized, Y_train)\n",
    "predicted_labels = clfrNB2.predict(X_test_vectorized)\n",
    "score = accuracy_score(Y_test, predicted_labels)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb36dec",
   "metadata": {},
   "source": [
    "## Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18398cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48717160066641035"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer().fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "clfrNB3 = ComplementNB()\n",
    "clfrNB3.fit(X_train_vectorized, Y_train)\n",
    "predicted_labels = clfrNB3.predict(X_test_vectorized)\n",
    "score = accuracy_score(Y_test, predicted_labels)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dddb7a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51759579648853"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer().fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "clfrNB3 = ComplementNB()\n",
    "clfrNB3.fit(X_train_vectorized, Y_train)\n",
    "predicted_labels = clfrNB3.predict(X_test_vectorized)\n",
    "score = accuracy_score(Y_test, predicted_labels)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb5d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
